{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import shutil\n",
    "import gc\n",
    "from myFunctions import *\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert PDF to JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_in = './PDF/'\n",
    "folder_out = './BBox_Label_Tool/Images/001/'\n",
    "\n",
    "for input_pdf in os.listdir(folder_in):\n",
    "\n",
    "    pages = convert_from_path(folder_in+input_pdf, 400)\n",
    "    \n",
    "    image = pages[0]\n",
    "    image = np.array(image)\n",
    "    height, width, depth = image.shape\n",
    "    imgScale = 0.2\n",
    "    newX,newY = image.shape[1]*imgScale, image.shape[0]*imgScale\n",
    "    resized = cv2.resize(image,(int(newX),int(newY)))\n",
    "    small = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    cv2.imwrite(folder_out+input_pdf[:-4] +'.jpg', small)\n",
    "\n",
    "\n",
    "del pages\n",
    "del image\n",
    "del imgScale\n",
    "del newX\n",
    "del newY\n",
    "del resized\n",
    "del small\n",
    "del height, width, depth\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Boxes Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, do the bounding box labelling at this point. You need to navigate to the folder BBox_Label_Tool and run the file main_jpg.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to the \"Data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_images = './BBox_Label_Tool/Images/001/'\n",
    "folder_labels = './BBox_Label_Tool/Labels/001/'\n",
    "folder_images_out = \"./data/train/images/\"\n",
    "folder_labels_out = \"./data/train/boxes/\"\n",
    "\n",
    "for file in os.listdir(folder_images):\n",
    "    if file[:-4] != \"bible_1\":\n",
    "        shutil.copyfile(folder_images + file , folder_images_out+ file)\n",
    "for file in os.listdir(folder_labels):\n",
    "    if file[:-4] != \"bible_1\":\n",
    "        shutil.copyfile(folder_labels + file , folder_labels_out+ file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = './data/train/images/'\n",
    "label_folder = './data/train/boxes/'\n",
    "transcription_folder = './data/train/transcriptions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = []\n",
    "label_list = []\n",
    "transcription_list=[]\n",
    "ID_list=[]\n",
    "for file in os.listdir(label_folder):\n",
    "    ID = file[:-4]\n",
    "    ID_list.append(ID)\n",
    "    file_list.append(image_folder+ID + \".jpg\")\n",
    "    label_list.append(label_folder + ID + \".txt\")\n",
    "    transcription_list.append(transcription_folder+ID+\".txt\")\n",
    "\n",
    "rect_list = []\n",
    "for fname in label_list:\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "        rectangles = []\n",
    "        for i, line in enumerate(content):\n",
    "            line= line.replace('\\n', '')\n",
    "            line= line.replace(' word', '')\n",
    "            if i > 0:\n",
    "                \n",
    "                x, y, x2, y2 = line.split(' ')\n",
    "                w = int(x2) - int(x)\n",
    "                h = int(y2) - int(y)\n",
    "                rectangles.append([int(x), int(y), w, h])\n",
    "                   \n",
    "        rect_list.append(rectangles)\n",
    "\n",
    "word_list = []\n",
    "for fname in transcription_list:\n",
    "    words = []\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()        \n",
    "        for i, line in enumerate(content):\n",
    "            line= line.replace('\\n', '')\n",
    "            words.append(line)     \n",
    "        \n",
    "    else:\n",
    "        open(fname, \"a\").close()\n",
    "    \n",
    "    word_list.append(words)\n",
    "        \n",
    "max_h = 0\n",
    "max_w = 0\n",
    "\n",
    "data = []\n",
    "for idx in range(len(file_list)):\n",
    "    img = cv2.imread(file_list[idx], 0)\n",
    "    #img = img/255\n",
    "    #img = img.astype(np.uint8)\n",
    "    data.append([img, rect_list[idx], word_list[idx], ID_list[idx]])\n",
    "    height, width = img.shape\n",
    "    if height > max_h:\n",
    "        max_h = height\n",
    "    if width > max_w:\n",
    "        max_w = width\n",
    "\n",
    "new_data = []\n",
    "for image, rect, word, ID in data:\n",
    "    image, new_rect = pad_image(image, rect, max_w, max_h)\n",
    "    if len(word) == 0:\n",
    "        print(\"The file \" + str(ID) + \" does not have any words transcription.\")\n",
    "    new_data.append([image, new_rect, word, ID])\n",
    "\n",
    "data = new_data\n",
    "del file_list\n",
    "del label_list\n",
    "del transcription_list\n",
    "del ID_list\n",
    "del rect_list\n",
    "del word_list\n",
    "del new_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if number of words == number of boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you need to do the transcription file. One \".txt\" file per image, in the folder './data/train/transcriptions/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = []\n",
    "for selected_idx in range(len(data)):\n",
    "    image = data[selected_idx][0]\n",
    "    rects = data[selected_idx][1]\n",
    "    words = data[selected_idx][2]\n",
    "    #draw_rects(image, rects)\n",
    "    #print(words)\n",
    "    if len(words) != len(rects):\n",
    "        print(\"Not the same number of rectangles and words!\")\n",
    "        print(\"Words in txt file: \" + str(len(words)))\n",
    "        print(\"Boxes in txt file : \" + str(len(rects)))\n",
    "        draw_rects(image, rects)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            x,y,w,h = rects[i]\n",
    "        \n",
    "            word_image = image[y:(y+h), x:(x+w)]\n",
    "            data_words.append([word_image, words[i]])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data (and squeeze the images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images will have the shape (661, 935)\n"
     ]
    }
   ],
   "source": [
    "squeeze = False\n",
    "\n",
    "if squeeze:\n",
    "    new_data = []\n",
    "    for image, rect, words, ID in data:\n",
    "        new_image, new_rect = squeeze_image(image,rect, 0.8, 0.8)\n",
    "        h, w = new_image.shape\n",
    "        desired_h, desired_w= new_image.shape\n",
    "        new_h = (h // 32)*32\n",
    "        new_w = (w // 32)*32\n",
    "        \n",
    "        y_min = (h - new_h)//2\n",
    "        x_min = (w - new_w)//2\n",
    "        \n",
    "        new_image2, new_rect2 = resize_image(new_image, new_rect, x_min, y_min, new_w, new_h, with_border_rect = True)\n",
    "        new_data.append([new_image2, new_rect2, words, ID])\n",
    "    data = new_data\n",
    "    del new_data\n",
    "    gc.collect()\n",
    "else:\n",
    "    max_w = 0\n",
    "    max_h = 0\n",
    "    for image, rect,words, ID in data:\n",
    "        h, w = image.shape\n",
    "        if h > max_h:\n",
    "            max_h = h\n",
    "        if w > max_w:\n",
    "            max_w = w\n",
    "    desired_w=max_w\n",
    "    desired_h=max_h\n",
    "\n",
    "print(\"The images will have the shape \" + str((desired_w,desired_h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the augmented dataset (It may compute for a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the initial dataset is 29\n",
      "The size of the augmented dataset is 1160\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the initial dataset is \" + str(len(data)))\n",
    "\n",
    "augmented_dataset = []\n",
    "\n",
    "for image, rects, words, ID in data:\n",
    "    for blur_coef in range(2):\n",
    "        if blur_coef == 0:\n",
    "            blur = image\n",
    "        else:\n",
    "            blur = cv2.blur(image,(blur_coef,blur_coef))\n",
    "        \n",
    "        \n",
    "        bright_image = blur.copy()\n",
    "        m = np.mean(bright_image)\n",
    "\n",
    "        for mean_cible in [m-50, m-25, m, m+25, m+50]:\n",
    "            bright_image = blur.copy()\n",
    "            bright_img = uniforming_brightness(bright_image, mean_cible)\n",
    "            #augmented_dataset.append([bright_img, rects, words, ID])\n",
    "            for width_squeeze_coef in range(80, 100,16):\n",
    "                width_squeeze_coef = width_squeeze_coef/100\n",
    "                (squeeze_img, squeeze_rects) = squeeze_image(bright_img,rects, width_squeeze_coef, 1)\n",
    "                padded_image, padded_rects = pad_image(squeeze_img, squeeze_rects, desired_w, desired_h)\n",
    "                augmented_dataset.append([padded_image, padded_rects,words, ID])\n",
    "            for height_squeeze_coef in range(80, 100,16):\n",
    "                height_squeeze_coef = height_squeeze_coef/100\n",
    "                (squeeze_img, squeeze_rects) = squeeze_image(bright_img,rects, 1, height_squeeze_coef)\n",
    "                padded_image, padded_rects = pad_image(squeeze_img, squeeze_rects, desired_w, desired_h)\n",
    "                augmented_dataset.append([padded_image, padded_rects, words, ID])\n",
    "        \n",
    "print(\"The size of the augmented dataset is \" + str(len(augmented_dataset)))\n",
    "                \n",
    "#del data\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some random images to check if everything went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    idx = random.randint(0,len(augmented_dataset))\n",
    "    draw_rects(augmented_dataset[idx][0], augmented_dataset[idx][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save into a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './big_data/train/augmented_images/'\n",
    "\n",
    "try:\n",
    "    os.listdir(folder)\n",
    "except:\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for the_file in os.listdir(folder):\n",
    "    \n",
    "    file_path = os.path.join(folder, the_file)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "for i in range(len(augmented_dataset)):\n",
    "    image = augmented_dataset[i][0]\n",
    "    rects = augmented_dataset[i][1]\n",
    "    ID = augmented_dataset[i][3]\n",
    "    with open(folder+ID + \"_\" +str(i)+'.txt', 'a') as the_file:\n",
    "        the_file.write(str(len(rects)) + '\\n')\n",
    "        for j in range(len(rects)):\n",
    "            the_file.write(str(rects[j][0]) +' '+str(rects[j][1]) +' '+str(rects[j][2]) + \\\n",
    "                           ' '+str(rects[j][3])+' word\\n')\n",
    "    cv2.imwrite(folder+ID + \"_\" +str(i)+'.png', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the individual words and save them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './big_data/train/words_images/'\n",
    "try:\n",
    "    os.listdir(folder)\n",
    "except:\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "for the_file in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, the_file)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 175280 extracted words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_width = 256\n",
    "max_height = 75\n",
    "\n",
    "unique_sequence = uniqueid()\n",
    "\n",
    "data_words = []\n",
    "with open(folder+\"labels\"+'.txt', 'a') as the_file:\n",
    "    for selected_idx in range(len(augmented_dataset)):\n",
    "        image = augmented_dataset[selected_idx][0]\n",
    "        rects = augmented_dataset[selected_idx][1]\n",
    "        words = augmented_dataset[selected_idx][2]\n",
    "        \n",
    "        if len(words) != len(rects):\n",
    "            print(\"Not the same number of rectangles and words!\")\n",
    "            print(len(words))\n",
    "            print(len(rects))\n",
    "            draw_rects(image, rects)\n",
    "        else:\n",
    "            for i in range(len(rects)):\n",
    "                x,y,w,h = rects[i]\n",
    "                word_image = image[y:(y+h), x:(x+w)]\n",
    "                id = next(unique_sequence)\n",
    "                new_image, _ = pad_image(word_image, [], max_width, max_height)\n",
    "                cv2.imwrite(folder+str(id)+'.png', new_image)\n",
    "                the_file.write(str(id) +' '+ str(words[i])+ \"\\n\")\n",
    "                data_words.append([new_image, words[i]])\n",
    "            \n",
    "print(\"There are \" + str(len(data_words)) + \" extracted words.\")\n",
    "\n",
    "del augmented_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
